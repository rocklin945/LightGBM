# 🔄 模型优化更新说明

## 📊 本次更新内容

### ✅ 主要改进

#### 1. 特征精简（94 → 50）
- **优化前**：94 个特征，包含很多冗余和低价值特征
- **优化后**：50 个核心特征，保留最重要的风险因素
- **效果**：提高训练效率，降低过拟合风险，更易理解

#### 2. 数据量增加（100 → 200）
- **优化前**：100 条样本，数据量不足导致模型不稳定
- **优化后**：200 条样本，更充足的训练数据
- **效果**：提高模型精度和泛化能力

#### 3. 自动标注功能
- **新增**：`auto_label.py` 和 `check_labels.py` 脚本
- **自动标注率**：约 85% 的数据可自动标注
- **规则覆盖**：
  - ✅ 安全可合并（纯文档/测试、Owner小改动等）
  - ❌ 必须拒绝（支付/PII、CI失败、大改动等）
- **效果**：大幅减少人工标注工作量，从 200 条降至约 30 条

#### 4. 样本平衡优化
- **问题**：之前标注不平衡导致精确率为 0
- **解决**：
  - 自动标注规则更平衡（目标 40-60% 可合并）
  - `check_labels.py` 实时监控样本比例
  - 提供警告和建议
- **效果**：避免模型偏向单一类别

#### 5. 阈值调整（0.75 → 0.6）
- **优化前**：0.75 阈值过高，不易通过
- **优化后**：0.6 阈值更宽松，符合 AI 优先理念
- **效果**：更多 MR 可以自动合并，提高效率

### 📈 特征对比

| 类别 | 优化前（94特征） | 优化后（50特征） | 说明 |
|------|------------------|------------------|------|
| 代码变更基础 | 8 | 5 | 保留核心指标 |
| 文件类型分布 | 9 | 5 | 合并相似特征 |
| 代码结构变更 | 9 | 4 | 去除低价值特征 |
| 依赖与集成 | 7 | 4 | 保留关键变更 |
| 测试覆盖 | 8 | 5 | 聚焦覆盖率 |
| CI/CD 质量 | 9 | 6 | 保留质量指标 |
| 作者近期表现 | 7 | - | 合并到作者质量 |
| 作者长期历史 | 7 | - | 合并到作者质量 |
| 作者质量 | - | 9 | 整合作者相关 |
| 提交行为 | 6 | 3 | 保留核心指标 |
| 时间相关 | 5 | - | 去除（低相关性） |
| 权限角色 | 4 | 3 | 保留核心权限 |
| 仓库文件热度 | 6 | - | 去除（难获取） |
| 风险信号 | 9 | 6 | 保留关键风险 |

### 🚀 新增脚本

#### 1. `auto_label.py` - 自动标注工具
```bash
python auto_label.py
```
**功能**：
- 基于 10+ 条规则自动标注约 85% 的数据
- 提供详细的标注原因统计
- 检查样本平衡性并给出警告

**规则示例**：
- ✅ 纯文档改动 → 可合并
- ❌ 涉及支付 → 不可合并
- ❌ CI 构建失败 → 不可合并
- ✅ Owner + 小改动 + CI 全过 → 可合并

#### 2. `check_labels.py` - 标注状态检查
```bash
python check_labels.py
```
**功能**：
- 快速查看标注进度
- 检查样本平衡性
- 提供下一步操作建议
- 显示未标注数据的行号

### 🔧 配置优化

#### `config.py` 主要更新
1. **特征定义**：50 个核心特征，10 大类别
2. **强制拒绝条件**：简化为 2 个核心条件
   - `involves_payment == 1`
   - `ci_build_passed == 0`
3. **自动合并阈值**：0.6（之前 0.75）

#### `1_data_labeling.py` 主要更新
1. **数据量**：200 条（之前 100 条）
2. **特征数**：50 个（之前 94 个）
3. **界面优化**：
   - 关键指标快速预览
   - AI 建议判断
   - 进度实时显示
4. **数据生成**：更真实的分布
   - 风险信号概率降低（如支付 2%，而非 50%）
   - 使用多种分布（指数、泊松、Beta 等）

### 📖 使用流程（新）

```bash
# 1. 生成初始数据（200条，50特征）
python 1_data_labeling.py

# 2. 自动标注（约85%）⭐ 新增
python auto_label.py

# 3. 人工标注剩余15%（约30条）
python 1_data_labeling.py

# 4. 检查标注状态 ⭐ 新增
python check_labels.py

# 5. 训练模型（至少150条）
python 2_train_model.py

# 6. 验证模型
python 3_validate_model.py
```

## 🎯 解决的问题

### 问题 1：精确率为 0 ❌
**原因**：
- 样本不平衡（过度偏向"不可合并"）
- 测试集太小
- 标注质量不一致

**解决方案**：✅
- 自动标注规则确保 40-60% 的平衡比例
- 增加数据量到 200 条
- `check_labels.py` 实时监控并警告

### 问题 2：数据太少（100 条）❌
**原因**：
- 100 条不足以训练稳定的模型
- 测试集分割后更少

**解决方案**：✅
- 增加到 200 条
- 建议至少标注 150 条再训练

### 问题 3：特征太多（94 个）❌
**原因**：
- 很多特征冗余或低价值
- 增加标注负担
- 容易过拟合

**解决方案**：✅
- 精简到 50 个核心特征
- 去除时间相关、仓库热度等难获取或低相关性特征
- 整合作者相关特征

### 问题 4：标注工作量大 ❌
**原因**：
- 需要人工标注 200 条
- 很多数据其实规则可以判断

**解决方案**：✅
- 新增 `auto_label.py`，自动标注约 170 条
- 只需人工标注约 30 条不确定样本
- 减少约 85% 的人工工作量

## 📋 下一步操作

### 第一次使用（推荐流程）

1. **删除旧数据**（已完成 ✅）
   ```bash
   # 旧数据已自动删除
   ```

2. **生成新数据**
   ```bash
   python 1_data_labeling.py
   # 会生成 200 条数据，50 个特征
   ```

3. **自动标注**
   ```bash
   python auto_label.py
   # 自动标注约 170 条（85%）
   ```

4. **检查状态**
   ```bash
   python check_labels.py
   # 查看标注进度和样本平衡性
   ```

5. **人工标注**
   ```bash
   python 1_data_labeling.py
   # 只标注剩余约 30 条不确定样本
   ```

6. **再次检查**
   ```bash
   python check_labels.py
   # 确认样本比例在 40-60% 之间
   # 确认已标注至少 150 条
   ```

7. **训练模型**
   ```bash
   python 2_train_model.py
   # 查看精确率是否 > 0
   # 查看 AUC、F1 等指标
   ```

8. **验证模型**
   ```bash
   python 3_validate_model.py
   # 在验证集上测试
   ```

## 🔍 预期效果

### 模型性能
- **精确率**：> 0.5（之前 0）
- **召回率**：> 0.5
- **F1-score**：> 0.5
- **AUC**：> 0.7

### 样本分布
- **可合并**：40-60%
- **不可合并**：40-60%
- **样本总数**：至少 150 条

### 工作效率
- **人工标注**：从 200 条 → 30 条（减少 85%）
- **标注时间**：从约 3 小时 → 约 30 分钟

## ⚠️ 注意事项

1. **首次运行**会重新生成数据，之前的标注会丢失（已备份）
2. **确保样本平衡**：用 `check_labels.py` 检查比例
3. **至少 150 条**：数据太少会导致模型不稳定
4. **规则调整**：可以根据实际情况修改 `auto_label.py` 中的规则

## 📞 问题反馈

如果遇到问题：
1. 运行 `python check_labels.py` 检查状态
2. 查看 `README.md` 了解详细说明
3. 检查样本比例是否在 40-60% 之间
4. 确保至少标注了 150 条数据

---

**更新时间**：2026-02-09  
**版本**：v2.0（精简版）
